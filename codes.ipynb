{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AddFK6qv_yse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1919c1d-d3d9-4e7c-9e11-156575303c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed text: data preprocessing important step natural language processing\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and numbers using regex\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # Join tokens back into a string\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Example text\n",
        "text = \"Data preprocessing is an important step in natural language processing!\"\n",
        "\n",
        "# Preprocess the text\n",
        "preprocessed_text = preprocess_text(text)\n",
        "print(\"Preprocessed text:\", preprocessed_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hey this is rohit your best friend\"\n",
        "stop_words = ['the','is','in','your','you']\n",
        "tokens = text.split()\n",
        "for token in tokens :\n",
        "  if token not in stop_words:\n",
        "    print(token)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZvjvmw7M5yG",
        "outputId": "e69218bc-7801-4602-d1d7-adb4761a02f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey\n",
            "this\n",
            "rohit\n",
            "best\n",
            "friend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "arffloader,classassigner(evaluation),crossvalidationfolad,classifier,classifierperformanceevaluater,textviewer -- knowledgeflow"
      ],
      "metadata": {
        "id": "uj9lE0GP176J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([['name',342],['rohit',10],['mohit',34]],columns = ['name','score'])\n",
        "\n",
        "# rename column name\n",
        "d = df.rename(columns = {'name':'new_name'})\n",
        "print(d)\n",
        "d.drop(columns = ['new_name'])\n",
        "# Filter rows based on a boolean condition\n",
        "print(df.query('Age > 30'))\n",
        "# Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Fill missing values with a specified value\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Sort DataFrame by values in a column\n",
        "df = df.sort_values(by='Age_in_Years', ascending=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "21wW1me119JB",
        "outputId": "f636dddb-e61b-42df-97f3-1d14916bfc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  new_name  score\n",
            "0     name    342\n",
            "1    rohit     10\n",
            "2    mohit     34\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   score\n",
              "0    342\n",
              "1     10\n",
              "2     34"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3a45ce1-a8a8-4b98-adf3-955a3ce0cef4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3a45ce1-a8a8-4b98-adf3-955a3ce0cef4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3a45ce1-a8a8-4b98-adf3-955a3ce0cef4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3a45ce1-a8a8-4b98-adf3-955a3ce0cef4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a2e9b20-0f49-43ab-a64e-58960bbb3626\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a2e9b20-0f49-43ab-a64e-58960bbb3626')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a2e9b20-0f49-43ab-a64e-58960bbb3626 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"d\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185,\n        \"min\": 10,\n        \"max\": 342,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          342,\n          10,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Sum of all elements\n",
        "result = np.sum(arr_2d)\n",
        "\n",
        "# Mean of all elements\n",
        "result = np.mean(arr_2d)\n",
        "\n",
        "# Maximum element\n",
        "result = np.max(arr_2d)\n",
        "\n",
        "# Minimum element\n",
        "result = np.min(arr_2d)"
      ],
      "metadata": {
        "id": "YdhyRbj85kCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "X_test,X_train,y_test,y_train = train_test_split(df.text_part,df.class_label_part, test_size = 0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "rFosLGD66kiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFN41WjO884m",
        "outputId": "98df037d-39df-4272-848d-17ea1f5ef8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fishers method to select k features:\n",
        "# Assignment 05\n",
        "# Step 1: Load the dataset data =\n",
        "pd.read_csv('page_block.csv')\n",
        "# Step 2: Compute the mean of attribute values against both class labels\n",
        "mean_negative_class = data[data['class'] == 'negative'].mean()\n",
        "mean_positive_class = data[data['class'] == 'positive'].mean()\n",
        "# Step 3: Compute the standard deviation of attribute values against both class\n",
        "labels std_negative_class = data[data['class'] == 'negative'].std()\n",
        "std_positive_class = data[data['class'] == 'positive'].std()\n",
        "# Step 4: Score (f) for each attribute f_score = (mean_positive_class -\n",
        "mean_negative_class) / (std_positive_class + std_negative_class)\n",
        "# Step 5: Assign a rank for each attribute ranked_features\n",
        "= f_score.rank(ascending=False)\n",
        "# Select the top k ranked features k = 5 #\n",
        "Replace with the desired value of k\n",
        "selected_features = ranked_features.nlargest(k)\n",
        "print(selected_features)\n"
      ],
      "metadata": {
        "id": "X1fHk8PwBvzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn python implementation--\n",
        "# importing libraries\n",
        "import numpy as nm\n",
        "import matplotlib.pyplot as mtp\n",
        "import pandas as pd\n",
        "\n",
        "#importing datasets\n",
        "data_set= pd.read_csv('user_data.csv')  # id gender age salary purchased\n",
        "\n",
        "#Extracting Independent and dependent Variable\n",
        "x= data_set.iloc[:, [2,3]].values\n",
        "y= data_set.iloc[:, 4].values\n",
        "\n",
        "# Splitting the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)\n",
        "\n",
        "#feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "st_x= StandardScaler()\n",
        "x_train= st_x.fit_transform(x_train)\n",
        "x_test= st_x.transform(x_test)\n",
        "# 1st way-----------------------------\n",
        "#Fitting K-NN classifier to the training set\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )\n",
        "classifier.fit(x_train, y_train)\n",
        "#Predicting the test set result\n",
        "y_pred= classifier.predict(x_test)\n",
        "#Creating the Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm= confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# using Decision tree everything will be same change model\n",
        "# 2nd way------------------------------\n",
        "#Fitting Decision Tree classifier to the training set\n",
        "From sklearn.tree import DecisionTreeClassifier\n",
        "classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "classifier.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "RxjR412NKdkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q05EVFF3RRLB",
        "outputId": "a73416a0-dcab-4d23-d46b-c13d8f126a99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/Buy_Computer.csv')\n",
        "# Step 2: Compute the entropy (info(dataset)) of the entire dataset\n",
        "def entropy(labels):\n",
        "n_labels = len(labels)\n",
        "if n_labels <= 1:\n",
        "return 0 value, counts = np.unique(labels,\n",
        "return_counts=True)\n",
        "probs = counts / n_labels\n",
        "n_classes = np.count_nonzero(probs)\n",
        "if n_classes <= 1:\n",
        "return 0\n",
        "ent = 0. for i\n",
        "in probs:\n",
        "ent -= i * np.log2(i)\n",
        "return ent\n",
        "dataset_entropy =\n",
        "entropy(data['class'])\n",
        "# Step 3: Compute InfoA(Dataset) for each attribute A in the dataset def\n",
        "info_A(dataset, attribute):\n",
        "info = 0 for value in\n",
        "dataset[attribute].unique():\n",
        "subset = dataset[dataset[attribute] == value] info +=\n",
        "(len(subset) / len(dataset)) * entropy(subset['class']) return\n",
        "info\n",
        "info_A_values = {} for attribute\n",
        "in data.columns[:-1]:\n",
        "info_A_values[attribute] = info_A(data, attribute)\n",
        "# Step 4: Compute Information Gain (A) for each attribute A in the dataset def\n",
        "information_gain(dataset_entropy, info_A_values):\n",
        "gain_values = {} for attribute, info_A in\n",
        "info_A_values.items():\n",
        "gain_values[attribute] = dataset_entropy - info_A\n",
        "return gain_values\n",
        "information_gain_values = information_gain(dataset_entropy,\n",
        "info_A_values)\n",
        "# Step 5: Select k attributes with the highest information gain\n",
        "k = 3 # Replace with the desired value of k selected_attributes\n",
        "= sorted(information_gain_values,\n",
        "key=information_gain_values.get, reverse=True)[:k]\n",
        "print(selected_attributes)"
      ],
      "metadata": {
        "id": "LO-q1cZKTEh0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 6 for creating decision tree general and binary tree"
      ],
      "metadata": {
        "id": "-1q8GGCzYWsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Load the data data =\n",
        "pd.read_csv(\"vehicle.csv\")\n",
        "# Assuming preprocessing might involve handling missing\n",
        "# values, encoding categorical variables, etc.\n",
        "# For demonstration, let's assume there's no preprocessing required in\n",
        "# this case.\n",
        "# Function to calculate Information Gain def\n",
        "import numpy as np\n",
        "\n",
        "def information_gain(data, attribute_name, target_name):\n",
        "    entropy_total = calculate_entropy(data[target_name])\n",
        "    values, counts = np.unique(data[attribute_name], return_counts=True)\n",
        "    weighted_entropy = np.sum([(counts[i] / np.sum(counts)) *\n",
        "                                calculate_entropy(data.where(data[attribute_name] == values[i]).dropna()[target_name])\n",
        "                                for i in range(len(values))])\n",
        "    return entropy_total - weighted_entropy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Gini Index\n",
        "def gini_index(data, attribute_name, target_name):\n",
        "    gini_total = calculate_gini(data[target_name])\n",
        "    values, counts = np.unique(data[attribute_name], return_counts=True)\n",
        "    weighted_gini = np.sum([(counts[i] / np.sum(counts)) *\n",
        "                            calculate_gini(data.where(data[attribute_name] == values[i]).dropna()[target_name])\n",
        "                            for i in range(len(values))])\n",
        "    return gini_total - weighted_gini\n",
        "\n",
        "# Function to calculate Gain Ratio\n",
        "def gain_ratio(data, attribute_name, target_name):\n",
        "    info_gain = information_gain(data, attribute_name, target_name)\n",
        "    split_info = calculate_entropy(data[attribute_name])\n",
        "    return info_gain / split_info\n",
        "\n",
        "# Function to calculate entropy\n",
        "def calculate_entropy(target):\n",
        "    entropy = 0\n",
        "    values, counts = np.unique(target, return_counts=True)\n",
        "    for i in range(len(values)):\n",
        "        prob = counts[i] / np.sum(counts)\n",
        "        entropy -= prob * np.log2(prob)\n",
        "    return entropy\n",
        "\n",
        "# Function to calculate Gini Index\n",
        "def calculate_gini(target):\n",
        "    gini = 1\n",
        "    values, counts = np.unique(target, return_counts=True)\n",
        "    for i in range(len(values)):\n",
        "        prob = counts[i] / np.sum(counts)\n",
        "        gini -= prob ** 2\n",
        "    return gini\n",
        "\n",
        "# Compute split points for each attribute using the specified strategies\n",
        "split_points_info_gain = {col: information_gain(data, col, 'Fuel_Type') for col in data.columns if col != 'Fuel_Type'}\n",
        "split_points_gini_index = {col: gini_index(data, col, 'Fuel_Type') for col in data.columns if col != 'Fuel_Type'}\n",
        "split_points_gain_ratio = {col: gain_ratio(data, col, 'Fuel_Type') for col in data.columns if col != 'Fuel_Type'}\n",
        "\n",
        "print(\"Split points using Information Gain:\", split_points_info_gain)\n",
        "print(\"Split points using Gini Index:\", split_points_gini_index)\n",
        "print(\"Split points using Gain Ratio:\", split_points_gain_ratio)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "import graphviz\n",
        "\n",
        "X = data.drop(columns=['Fuel_Type'])\n",
        "X = pd.get_dummies(X, columns=['Car_Name', 'Seller_Type', 'Transmission'])\n",
        "y = data['Fuel_Type']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "def build_decision_tree(X_train, y_train, binary=True):\n",
        "    # Initialize Decision Tree Classifier\n",
        "    if binary:\n",
        "        tree = DecisionTreeClassifier(splitter='best')\n",
        "    else:\n",
        "        tree = DecisionTreeClassifier()\n",
        "\n",
        "    # Fit the model\n",
        "    tree.fit(X_train, y_train)\n",
        "    return tree\n",
        "\n",
        "def visualize_decision_tree(tree, feature_names, class_names, filename):\n",
        "    dot_data = export_graphviz(tree, out_file=None, feature_names=feature_names, class_names=class_names, filled=True, rounded=True, special_characters=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    graph.render(filename, format='png')  # Save the tree visualization as a PNG file\n",
        "\n",
        "# For a binary tree:\n",
        "binary_tree = build_decision_tree(X_train, y_train, binary=True)\n",
        "visualize_decision_tree(binary_tree, feature_names=X_train.columns, class_names=y_train.unique(), filename='binary_tree')\n",
        "\n",
        "# For a general tree:\n",
        "general_tree = build_decision_tree(X_train, y_train, binary=False)\n",
        "visualize_decision_tree(general_tree, feature_names=X_train.columns, class_names=y_train.unique(), filename='general_tree')\n",
        "\n",
        "def predict_with_decision_tree(tree, X_test):\n",
        "    # Predict class labels for test data\n",
        "    y_pred = tree.predict(X_test)\n",
        "    return y_pred\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X_test is already defined\n",
        "# For a binary tree:\n",
        "binary_tree_predictions = predict_with_decision_tree(binary_tree, X_test)\n",
        "\n",
        "# For a general tree:\n",
        "general_tree_predictions = predict_with_decision_tree(general_tree, X_test)\n",
        "\n",
        "# Calculate accuracy for Binary Tree Model\n",
        "accuracy = accuracy_score(y_test, binary_tree_predictions)\n",
        "print(\"Accuracy for Binary Tree Model:\", accuracy)\n",
        "\n",
        "# Calculate accuracy for General Tree Model\n",
        "accuracy = accuracy_score(y_test, general_tree_predictions)\n",
        "print(\"Accuracy for General Tree Model:\", accuracy)\n"
      ],
      "metadata": {
        "id": "NR6pO6OSYfjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asg 07 Baiyes classifier"
      ],
      "metadata": {
        "id": "Yxoo-ZtQa4Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a. Prepare the dictionary which counts the number of “yes” and “no”\n",
        "# class labels for each nominal value in an attribute.\n",
        "import pandas as pd\n",
        "\n",
        "def count_class_labels(df, attribute):\n",
        "    # Prepare a dictionary that counts the number of \"yes\" and \"no\" class labels for each nominal value in an attribute\n",
        "    counts_dict = {}\n",
        "    unique_values = df[attribute].unique()\n",
        "    for value in unique_values:\n",
        "        counts_dict[value] = {\n",
        "            'yes': df[(df[attribute] == value) & (df['Buy_Computer'] == 'yes')].shape[0],\n",
        "            'no': df[(df[attribute] == value) & (df['Buy_Computer'] == 'no')].shape[0]\n",
        "        }\n",
        "    return counts_dict\n",
        "\n",
        "# Load the dataset\n",
        "# df = pd.read_csv('buys_computer.csv')\n",
        "data = pd.read_csv('/content/drive/MyDrive/Buy_Computer.csv')\n",
        "# Example usage:\n",
        "counts_dict = count_class_labels(data, 'age')\n",
        "print(counts_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLW9zPjcaXR9",
        "outputId": "476de1c1-3648-41c8-b208-db7f0761caca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'youth': {'yes': 2, 'no': 3}, 'middle_age': {'yes': 4, 'no': 0}, 'senior': {'yes': 3, 'no': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b.Compute the probability of the class labels (buys_computer=”yes”\n",
        "# or buys_computer= ”no”) for each nominal value in an attribute.\n",
        "def compute_class_label_probabilities(df, attribute):\n",
        "    class_label_probs = {}\n",
        "    unique_values = df[attribute].unique()\n",
        "    total_samples = len(df)\n",
        "    for value in unique_values:\n",
        "        value_df = df[df[attribute] == value]\n",
        "        yes_prob = value_df[value_df['buys_computer'] == 'yes'].shape[0] / total_samples\n",
        "        no_prob = value_df[value_df['buys_computer'] == 'no'].shape[0] / total_samples\n",
        "        class_label_probs[value] = {'yes': yes_prob, 'no': no_prob}\n",
        "    return class_label_probs\n",
        "\n",
        "# Example usage:\n",
        "class_label_probs = compute_class_label_probabilities(df, 'age')\n",
        "print(class_label_probs)\n",
        "\n",
        "# C. Using Bayes’ theorem compute the probability of instance X = (age =\n",
        "# youth, income = medium, student = yes, credit_rating = fair) against\n",
        "# class label (buys_computer=”yes” and buys_computer=”no”).\n",
        "\n",
        "\n",
        "def compute_bayes_probability(df, instance_values, class_label):\n",
        "    total_samples = len(df)\n",
        "    class_counts = df[class_label].value_counts()\n",
        "    class_probs = class_counts / total_samples\n",
        "    bayes_probs = {}\n",
        "\n",
        "    for label in class_probs.index:\n",
        "        prob = class_probs[label]\n",
        "\n",
        "        for attr, value in instance_values.items():\n",
        "            subset = df[df[attr] == value]\n",
        "            subset_count = subset[class_label].value_counts().get(label, 0)\n",
        "\n",
        "            prob *= (subset_count + 1) / (class_counts[label] + len(subset[attr].unique()))\n",
        "\n",
        "        bayes_probs[label] = prob\n",
        "\n",
        "    return bayes_probs\n",
        "# Define the instance X\n",
        "instance_values = {'age': 'youth', 'income': 'medium', 'student': 'yes', 'credit_rating': 'fair'}\n",
        "\n",
        "# Example usage:\n",
        "bayes_probs = compute_bayes_probability(df, instance_values, 'buys_computer')\n",
        "print(bayes_probs)\n",
        "\n",
        "def justify_bayes_probability(bayes_probs):\n",
        "    max_prob_label = max(bayes_probs, key=bayes_probs.get)\n",
        "    justification = f\"The instance is more likely to belong to class '{max_prob_label}' with a probability of {bayes_probs[max_prob_label]:.4f}\"\n",
        "    return justification\n",
        "\n",
        "# Example usage:\n",
        "justification = justify_bayes_probability(bayes_probs)\n",
        "print(justification)\n"
      ],
      "metadata": {
        "id": "80p7xl09b-Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 8 K means algo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_distance_matrix(data):\n",
        "    data = pd.get_dummies(data)  # Convert non-numeric data to numeric if needed\n",
        "    distance_matrix = np.zeros((len(data), len(data)))\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        for j in range(len(data)):\n",
        "            distance_matrix[i][j] = np.sqrt(np.sum((data.iloc[i] - data.iloc[j])**2))\n",
        "\n",
        "    return distance_matrix\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def k_means_clustering(k, data):\n",
        "    centroids = data.sample(n=k)\n",
        "    partitions = {}\n",
        "\n",
        "    while True:\n",
        "        clusters = {i: [] for i in range(k)}\n",
        "\n",
        "        # Assigning clusters\n",
        "        for index, row in data.iterrows():\n",
        "            distances = [np.sqrt(np.sum((row - centroids.iloc[i])**2)) for i in range(k)]\n",
        "            cluster_index = distances.index(min(distances))\n",
        "            clusters[cluster_index].append(index)\n",
        "\n",
        "        # Updating centroids\n",
        "        new_centroids_data = []\n",
        "        for key, value in clusters.items():\n",
        "            cluster_data = data.loc[value]\n",
        "            new_centroids_data.append(cluster_data.mean(axis=0))\n",
        "\n",
        "        new_centroids = pd.DataFrame(new_centroids_data)\n",
        "        if new_centroids.equals(centroids):\n",
        "            partitions = clusters\n",
        "            break\n",
        "\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return partitions, centroids\n",
        "\n",
        "# Example usage with a DataFrame `df`\n",
        "# k_value is the number of desired clusters.\n",
        "# partitions, final_centroids k_means_clustering(k_value, df)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_clusters(partitions, data):\n",
        "    colors = ['orange', 'blue', 'green', 'red', 'purple']  # Add more colors if needed\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    for i, indices in partitions.items():\n",
        "        cluster_data = data.loc[indices]\n",
        "        plt.scatter(cluster_data['x'], cluster_data['y'], c=colors[i], label=f'Cluster {i}')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "bDMvA5lNeM1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-McVykflRAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}